# PGSQL Statistics System – How a DBA Actually Uses It

<br>
<br>

- [PGSQL Statistics System – How a DBA Actually Uses It](#pgsql-statistics-system--how-a-dba-actually-uses-it)
  - [Scenario Overview](#scenario-overview)
  - [Step 1: What the Statistics System Really Is](#step-1-what-the-statistics-system-really-is)
  - [Step 2: A User Says “The Database Is Slow”](#step-2-a-user-says-the-database-is-slow)
  - [Step 3: Understanding Waiting vs Working](#step-3-understanding-waiting-vs-working)
  - [Step 4: Why Queries Appear Stuck](#step-4-why-queries-appear-stuck)
  - [Step 5: Table-Level Behavior](#step-5-table-level-behavior)
  - [Step 6: Index Reality Check](#step-6-index-reality-check)
  - [Step 7: Memory vs Disk Truth](#step-7-memory-vs-disk-truth)
  - [Step 8: Database-Wide Health](#step-8-database-wide-health)
  - [Step 9: WAL and Checkpoint Pressure](#step-9-wal-and-checkpoint-pressure)
  - [Step 10: Background Writer and Checkpoints](#step-10-background-writer-and-checkpoints)
  - [Step 11: Replication Visibility](#step-11-replication-visibility)
  - [Step 12: Archiving and Recovery Safety](#step-12-archiving-and-recovery-safety)
  - [Step 13: Statistics Are Not Instant](#step-13-statistics-are-not-instant)
  - [Step 14: Resetting Statistics Carefully](#step-14-resetting-statistics-carefully)
  - [Final Understanding Through This Flow](#final-understanding-through-this-flow)


<br>
<br>

## Scenario Overview

- A PGSQL server is running in production. Users complain that queries are slow, replication seems delayed, disk I/O spikes randomly, and sometimes sessions just hang. Nothing is obviously broken, but performance feels unstable.

- At this point, a DBA does not guess. A DBA looks at PGSQL statistics.

---

<br>
<br>

## Step 1: What the Statistics System Really Is

- PGSQL constantly observes itself.
- Every backend process keeps track of 
  - *what it is doing.*
  - *How many rows it reads.* 
  - *How many blocks it hits from memory.* 
  - *How often it writes to disk.* 
  - *How long it waits for locks.*

- These observations are collected into shared memory and exposed through `pg_stat_*` views.
- These views do not store configuration. They store **behavior**.
- If something feels slow, blocked, or unstable, the answer is usually already recorded here.

---

<br>
<br>

## Step 2: A User Says “The Database Is Slow”

- The first question is always: what is running right now?

A DBA checks:

```sql
SELECT pid, state, wait_event_type, wait_event, query
FROM pg_stat_activity
WHERE state <> 'idle'; -- <> means "not equals to".
```

This view shows one row per server process.

It immediately tells:

* who is connected
* what query is running
* whether the query is executing or waiting
* what it is waiting for

This is the live heartbeat of PGSQL.

**`pg_stat_activity`** is a system view that shows all database connections  - who is connected, what query they are running, their state, and what they are waiting on.

---

<br>
<br>

## Step 3: Understanding Waiting vs Working

- A backend can be **`active`** but still blocked.
- If `state` is **`active`** and `wait_event` is **`NULL`**, the query is running on CPU.
- If `wait_event_type` is **`Lock`**, the query is blocked by another transaction.
- If it is **`IO`**, PGSQL is waiting for disk.
- If it is **`LWLock`**, PGSQL is waiting for an internal shared-memory structure.
- This distinction tells a DBA whether the problem is CPU, disk, locks, or internal contention.

<br>
<details>
<summary><mark><b>wait_event_type and wait_event</b></mark></summary>
<br>

**`wait_event_type`**: This tells what category of thing a backend is waiting for.

- Common values:
  - **`Lock:`** waiting for a database lock held by another transaction.
  - **`LWLock:`** waiting for an internal lightweight pgsql lock (shared memory structures)
  - **`IO:`** waiting for disk read / write.
  - **`Client:`** waiting for cleint input / output.
  - **`Timeout:`** waiting for a timeout to expire
  - **`Activity:`** waiting on internal background activity
  - **`Extension:`** waiting inside an extension
  - **`NULL:`** not waiting, queyr is actively runnning on CPU.

**`wait_event`**: This gives the exact reason inside that category.
- Examples:
  - **`Lock`** -> **`transactionid`**, **`relation`**, **`tuple`**
  - **`LWLock`** -> **`WALWriteLock`**, **`BufferContent`**
  - **`IO`** -> **`DataFileRead`**, **`DataFileWrite`**
  - **`Client`** -> **`ClientRead`**, **`ClientWrite`**
  - **`Timeout`** -> **`StatementTimeout`**
  - **`NULL`** -> means the backend is working, not blocked.

</details>
<br>

<br>
<details>
<summary><mark><b>Explained with scenarios</b></mark></summary>
<br>

- A PGSQL backend can look active, but that doesnt mean it is actually doing work. The key is to look at **`state`**, **`wait_event_type`**, and **`wait_event`** together.

- We can check what a backend (session) is doing right now by looking at `pg_stat_activity`. The key columns are:
  - `state`: Usually `active` (running a query) or `idle`.
  - `wait_event_type` and `wait_event`: Tell us if the backend is working or waiting.

<br>
<br>

**1. Working on CPU (Query is actively running)**
- **`state = active`**
- **`wait_event_type = NULL`** (wait_event is NULL)
  - The query is using CPU right now - calculating, sorting etc...

**Example:**
```text
state           | active
query           | SELECT sum(amount) FROM orders WHERE date > '2025-01-01';
wait_event_type | NULL
wait_event      | NULL
```

> This query is busy crunching numbers on CPU. No Blocking.

<br>
<br>

**2. Waiting for a lock (Blocked by anoter session)**
- **`state = active`**
- **`wait_event_type = Lock`**
- **`wait_event`** = **`transactionid`** or **`relation`** or **`advisory`** etc.

**Example:**
```text
state           | active
query           | UPDATE users SET balance = balance - 100 WHERE id = 5;
wait_event_type | Lock
wait_event      | transactionid
```

> This UPDATE is waiting because another session has an uncommited transaction on the same row / table.

<br>
<br>

**3. Waiting for Disk I/O**
- **`state = active`**
- **`wait_event_type = IO`**
- Common **`wait_event`**: **`DataFileRead`**, **`DataFileWrite`**

**Example:**
```text
state           | active
query           | SELECT * FROM big_table WHERE id = 999999;
wait_event_type | IO
wait_event      | DataFileRead
```

> PGSQL is waiting for the disk to read a page (maybe not in memory / cache).

<br>
<br>

**4. Waiting for internal LWLock (Lightweight Lock - Internal Contention**
- **`state = active`**
-**` wait_event_type = LWLock`**
- Examples: **`buffer_content`**, **`lock_manager`**, **`WALWrite`**

**Examples:**
```text
state           | active
query           | INSERT INTO logs VALUES (...);
wait_event_type | LWLock
wait_event      | WALWrite
```

> Many sessions inserting at once - waiting to write to WAL safely.

<br>
<br>

**Why this everything matters?**
- If the backend have **`wait_event_type`** = **`NULL`** -> Proble is CPU (need better queries / indexes).
- Lots of **`Lock`** waits -> Lock contention (Long transactions, missing indexes).
- Lots of **`IO`** waits -> Disk slow (Need more RAM, faster storage, better caching).
- Lots of **`LWLock`** -> Interanal Contention (High concurrency, tune shared_buffers \ work_mem).


</details>
<br>

---

<br>
<br>

## Step 4: Why Queries Appear Stuck

- When sessions show `idle in transaction`, it means the client started a transaction and forgot to finish it.
- These sessions hold locks and block vacuum.
- **`pg_stat_activity`** exposes this clearly through `state` and `xact_start`.
- Long-running idle transactions are one of the most common production killers.

<br>
<details>
<summary><mark><b>Explained with scenarios!</b></mark></summary>
<br>

- We often see queries that look "stuck" in production - but the real rpoblem is idle in transaction sessions.

**What it means:**
- The client stated a transaction (BEGIN) but never finished it (**`COMMIT`** or **`ROLLBACK`**).
- The session is **`idle`** (not running any query right now), but it still holds locks and blocks other work.

**How we can spot it in pg_stat_activity:**
- **`state = idle in transaction`**
- **`xact_start`** shows when the transaction began (if it is old -> danger)

**Example:**
- When we run this query and see:
```bash
pid                | 12345
state              | idle in transaction
query              | (empty – no active query)
xact_start         | 2025-12-23 09:15:00
backend_start      | 2025-12-23 09:00:00
```

> This session started a transaction 45 mins ago and forgot to COMMIT or ROLLBACK. It is holding locks on rows or tables it touched earlier.

**What happens becuase of this?**
- Other sessions trying to UPDATE or DELETE the same rows get blocked -> appear stuck.
- VACCUM cannot clean old dead rows -> table bloat grows.
- AUTOVACCUM gets blocked -> more bloat and wraparound risk.

**Common Real-life cases:**
- Web app forgets to commit after an error.
- Developer runs BEGIN in psql and walks away.
- Long script starts transaction but craseshes before COMMIT.

**Run this and find them:**
```bash
SELECT pid, state, xact_start, query
FROM pg_stat_activity
WHERE state = 'idle in transaction'
ORDER BY xact_start;

# here xact means transaction and xact_start shows the time when the current transaction began
# it helps to identify long-running or stuck queries.

# backend_start shows the time when the backend (client connection) was started.
```

If you see old ones -> kill them safely:
```sql
SELECT pg_terminate_backend(12345);
```

**Summary:** Idle in transaction = forgottern open transaction -> holds locks, blocks vaccum, kills performance. Long ones are one of the top production killers.


</details>
<br>

---

<br>
<br>

## Step 5: Table-Level Behavior

Now the DBA asks: which tables are actually being touched?

```sql
SELECT relname, seq_scan, idx_scan, n_dead_tup
FROM pg_stat_user_tables
ORDER BY seq_scan DESC;
```

- This shows how tables are accessed.
- High sequential scans on large tables often indicate missing or unused indexes.
- High dead tuples indicate vacuum pressure.
- This view explains *why* disk usage grows and queries slow down over time.

<br>
<details>
<summary><mark><b>Explained with scenarios!</b></mark></summary>
<br>

**What is pg_stat_user_tables?**
- a system statistics view that shows activity and health info for user-created tables.
- It tells which tables are being used,
  - updated
  - vaccumed, or
  - bloated
  - things like row inserts, updates, deletes, and dead rows.

- When queries are slow or disk usage keeps growing, we need to look at the table-level activity. The best view for this is pg_stat_user_tables.

**Query to run:**
```sql
SELECT 
    relname AS table_name
    seq_scan,     -- Full table scan
    idx_scan,     -- Index scan
    n_tup_ins,    -- Rows inserted
    n_tup_upd,    -- Rows updated
    n_tup_del,    -- Rows deleted
    n_dead_tup    -- Dead Rows (need vaccum)
FROM pg_stat_user_tables
ORDER BY seq_scan DESC;
```

<br>
<br>

**Scenarios:**
**1. High `seq_scan` + Low `idx_scan` -> Missing or unused indexes:**

**Example:**
```text
table_name    | orders
seq_scan      | 15230
idx_scan      | 120
```
> This table is scaned fully 15k times but barely uses indexes -> queries are slow.
**Fix:** We should add proper indexes on `WHERE`, `JOIN`, or `ORDER BY` columns.

<br>
<br>

**2. High `n_dead_tup` -> Heavy Vaccum Pressure:**

**Example:**
```text
table_name    | logs
seq_scan      | 500
n_dead_tup    | 2,850,000
```

> 2.8 million dead rows waiting to be cleaned -> table bloat growing fast.

**Why:** Lots of `DELETE` / `UPDATE`, but `VACUUM` not keeping up.
**Fix:** Run `VACUUM (VERBOSE) logs;` or tune `autovacuum` for this table.

<br>
<br>

**3. High `n_tup_upd` + High `n_dead_tup` -> Update- heavy table:**

**Example:**
```text
table_name    | sessions
n_tup_upd     | 10,500,000
n_dead_tup    | 8,200,000
```

> Every `update` created a new row version -> huge bloat.

**Common in:** session tables, audit logs, status tracking.
**Fix:** More frequent VACUUM or consider table partitioning.

<br>
<br>

**4. High `idx_scan` + Low `seq_scan` -> Indexes are working well:**

**Example:**
```text
table_name    | customers
seq_scan      | 50
idx_scan      | 985,000
```

> Almost all queries use indexes -> healthy access pattern.

<br>
<br>

**5. High inserts + Growing size but low dead tuples -> Fast growing tabe:**

**Example:**
```text
table_name    | events
n_tup_ins     | 50,000,000
n_dead_tup    | 120,000
```

> Table is growing fast from inserts. Bloat is low (good vacuum).

**Action:** Monitor disk space, consider partitioning later.

<br>
<br>

**Run this query regularly:**
```sql
SELECT relname, seq_scan, idx_scan, n_tup_ins + n_tup_upd + n_tup_del AS changes, n_dead_tup
FROM pg_stat_user_tables
ORDER BY n_dead_tup DESC;
```

- Top rows with high `seq_scan` → candidates for new indexes.
- Top rows with high `n_dead_tup` → need VACUUM or autovacuum tuning.

**Summary:** `pg_stat_user_tables` shows us exactly which tables are misbehaving – missing indexes, bloat, or heavy write load. Check it when performance drops or disk fills up!



</details>
<br>

---

<br>
<br>

## Step 6: Index Reality Check

- Indexes existing does not mean indexes are used.

A DBA checks:

```sql
SELECT relname, indexrelname, idx_scan
FROM pg_stat_user_indexes
ORDER BY idx_scan ASC;
```

- Indexes with zero scans are unused.
- Unused indexes waste disk, slow writes, and confuse planners.
- `pg_stat_user_indexes` exposes index usefulness, not just existence.

<br>
<details>
<summary><mark><b>Explained with scenario!</b></mark></summary>
<br>

**What is pg_stat_user_indexes?**
- shows how indexes on  user tables are actually being used.
- It tells you which indexes pgsql is using,
  - how often they are scanned,
  - helps you to spot unused or unnecessary indexes.

- We know that having indexes is good, but existing indexes ≠ used indexes. 
- Many indexes just waste space and slow down writes without helping queries.
- The best waay tot check reality is `pg_stat_user_indexes`.

**Query to run:**
```sql
SELECT
    relname AS table_name,
    indexrelname AS index_name,
    idx_scan,         -- How many times this index was used
    idx_tup_read,     -- Tuples fetched by index
    idx_tup_fetch     -- Rows returned from table via index
FROM pg_stat_user_indexes
ORDER BY idx_scan ASC;
```

<br>
<br>

**All Possible Scenarios:**

**1. Zero or Very Low `idx_scan` -> Completely unused index:**
```text
table_name    | orders
index_name    | idx_orders_status_old
idx_scan      | 0
```

> This index has never been used (since last stats reset).

**Action:** Safe to DROP it - saves space and speeds up `INSERT` / `UPDATE` / `DELETE`.

<br>
<br>

**2. Low `idx_scan` on a large table -> Rarely used index:**
**Example:**
```text
table_name    | users
index_name    | idx_users_last_login
idx_scan      | 15
```

> Used only 15 times times (maybe an admin report runs monthly).

**Action:** Check if the query really needs it. If rare, consider dropping or keeping only if crucial.


<br>
<br>

**3. High `idx_scan` -> Actively used index:**
**Example:**
```text
table_name    | orders
index_name    | idx_orders_customer_date
idx_scan      | 1,250,000
```
> This index is heavily used -> queries are fast because of it.

**Action:** Keep it!

<br>
<br>

**4. Duplicate / Similar Indexes -> Redundant Indexes**
**Example:**
```text
table_name    | products
index_name    | idx_products_category
idx_scan      | 850,000
index_name    | idx_products_category_active
idx_scan      | 12
```

> Second index includes extra column but barely used -> probably redundant.

**Action:** Check if queries can use the first one. Drop the unused one.

<br>
<br>

**5. Index with high `idx_scan` but low `idx_tup_fetch` -> index used but not selective:**
**Example:**
```text
table_name    | logs
index_name    | idx_logs_level
idx_scan      | 500,000
idx_tup_fetch | 490,000
```

> Index scanned a lot but returns almost all rows -> not helpful

**Action:** Consider removing or making it more selective (combine with another column).

<br>
<br>

**Run this query regularly:**
```sql
SELECT relname, indexrelname, idx_scan
FROM pg_stat_user_indexes
WHERE idx_scan < 100    -- find rarely used ones
ORDER BY idx_scan ASC;
```

- Indexes with 0 scans → drop immediately.
- Low scans → investigate queries.
- Unused indexes slow down writes (INSERT/UPDATE/DELETE) and waste disk.

**Summary:** `pg_stat_user_indexes` shows the truth about index usage – many indexes look useful but are dead weight. Check `idx_scan` and drop the zeros – your writes will thank you!

</details>
<br>

---

<br>
<br>

## Step 7: Memory vs Disk Truth

The database feels slow. Is it disk or memory?

```sql
SELECT relname, heap_blks_read, heap_blks_hit
FROM pg_statio_user_tables;
```

- If hits are much higher than reads, data is served from shared buffers.
- If reads dominate, PGSQL is hitting disk.
- This single view tells whether tuning memory or storage will help.

<br>
<details>
<summary><mark><b>Explained with scenarios!</b></mark></summary>
<br>

**What is pg_statio_user_tables?**
- a system I/O statistics view for used tables.
- shows how much table data is beind read from memory vs disk, helping you to understand cache usage and disk I/O pressure.
- When the DB feels slow, we need to know the real culprit - memory (not enough cache) or disk (too many physical reads).
- The best view to check this is `pg_statio_user_tables`.

**Query to run:**
```sql
SELECT
    relname AS tables_name,
    heap_blks_read,      -- Blocks read from disk
    heap_blks_hit,       -- Blocks found in memory (shared_bufferes / cache)
    round(100.0 * heap_blks_hit / (heap_blks_hit + heap_blks_read + 1), 2) AS cache_hit_ratio
FROM pg_statio_user_tables
ORDER BY heap_blks_read DESC;
```

**All possible scenarios:**

**1. High `heap_blks_hit` >> `heap_blks_read` -> Good cache hit (mostly memory)**
**Example:**
```text
table_name       | customers
heap_blks_hit    | 9,850,000
heap_blks_read   | 150,000
cache_hit_ratio  | 98.50
```

> 98% data served from memory -> healthy

**Action:** No memory tunning needed. Problem is likely CPU or queries, not I/O.

<br>
<br>


**2. High `heap_blks_read` = or > `heap_blks_hit` -> Too many disk reads:**
**Example:**
```text
table_name       | orders_big
heap_blks_hit    | 2,100,000
heap_blks_read   | 4,800,000
cache_hit_ratio  | 30.43
```

> Only 30% cache hit -> hitting disk a lot -> slow queries

**Action:** Increase `shared_buffers`, add more RAM, or tuen queries to access less data.

<br>
<br>

**3. Very high reads on specific large tables -> Hot tables dont fit in memory:**
**Example:**
```text
table_name       | logs_archive
heap_blks_hit    | 50,000
heap_blks_read   | 3,200,000
cache_hit_ratio  | 1.54
```

> This huge tuple is scanned often but barely cached.

**Action:** Add better indexes (reduce scans), partition the table, or move old data to archive.

<br>
<br>

**4. Balanced But low overall hits -> System wide memory pressure:**
**Example:** (multiple tables show ~70-80% hit ratio)
```text
table_name    | sales_2025    | hit: 1.2M | read: 400k | ratio: 75%
table_name    | inventory     | hit: 800k | read: 300k | ratio: 72%
```

> Not terrible, but room for improvement across the board.
**Action:** Increase `shared_buffers` (aim for 90-95% cluster-wide), or check OS cache (effective_cache_size).

<br>
<br>

**5. Zero or low activity tables with some reads -> Cold data:**
**Example:**
```text
table_name      | old_reports
heap_blks_hit   | 5,000
heap_blks_read  | 80,000
```

> Rarely used table, reads only when accessed -> normal.

**Action:** No worry - expected for archive / cold tables.

<br>
<br>

**Quick cluster wide check:**
```sql
SHOW cache_hit_ratio;  

-- Or manual:

SELECT sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) * 100 AS overall_hit_ratio
FROM pg_statio_user_tables;
```

- 99%+ hit ratio → Memory is fine, look at queries/CPU.
- Below 95% → Add more RAM or increase shared_buffers.
- Below 90% → Urgent – disk I/O is killing performance.

**Summary**: `pg_statio_user_tables` reveals the truth: <mark><b>high</b></mark> `heap_blks_hit` = happy memory, <mark><b>high</b></mark> `heap_blks_read` = disk bottleneck. Check it before buying SSDs or adding RAM!

</details>
<br>


---

<br>
<br>

## Step 8: Database-Wide Health

A DBA zooms out to database level:

```
SELECT datname, xact_commit, xact_rollback, deadlocks, temp_files
FROM pg_stat_database;
```

High rollbacks indicate application errors.

Deadlocks indicate poor transaction design.

Temp files indicate insufficient work_mem or bad query plans.

This view summarizes how healthy each database is.

---

## Step 9: WAL and Checkpoint Pressure

When disk spikes appear, WAL is a suspect.

```
SELECT wal_records, wal_bytes, wal_buffers_full
FROM pg_stat_wal;
```

High WAL generation means heavy write workload.

Frequent WAL buffer full events indicate WAL pressure.

This explains fsync spikes and replication lag.

---

## Step 10: Background Writer and Checkpoints

A DBA checks whether backends are doing too much dirty work:

```
SELECT buffers_backend, buffers_clean, checkpoints_req
FROM pg_stat_bgwriter;
```

High backend writes mean background writer is not keeping up.

Frequent requested checkpoints indicate aggressive write patterns.

This directly impacts latency.

---

## Step 11: Replication Visibility

If replication exists, lag must be understood:

```
SELECT state, sent_lsn, replay_lsn, replay_lag
FROM pg_stat_replication;
```

This view shows how far standbys lag behind.

Replay lag reflects how stale read replicas are.

This helps DBAs decide whether replicas are safe for reads.

---

## Step 12: Archiving and Recovery Safety

For PITR setups, archiving must work:

```
SELECT archived_count, failed_count
FROM pg_stat_archiver;
```

Failures here mean backups are incomplete.

This view is critical for recovery confidence.

---

## Step 13: Statistics Are Not Instant

Statistics update lazily.

A running query does not update counters until it finishes or goes idle.

Within a transaction, statistics appear frozen.

This behavior is intentional and prevents inconsistent reads of stats.

A DBA must always remember this delay when diagnosing live systems.

---

## Step 14: Resetting Statistics Carefully

Statistics can be reset:

```
SELECT pg_stat_reset();
```

This clears history.

But it also resets autovacuum decision counters.

After a reset, ANALYZE should be run to rebuild planner visibility.

Statistics reset is a scalpel, not a hammer.

---

## Final Understanding Through This Flow

PGSQL statistics are PGSQL’s self-awareness.

They explain what is happening now, what happened recently, and where pressure exists.

A DBA does not guess performance problems. A DBA reads `pg_stat_*`.

If statistics make sense, performance stops being mysterious.
